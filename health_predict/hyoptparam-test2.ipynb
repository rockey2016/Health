{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/health/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon July 16 10:08:53 2018\n",
    "\n",
    "@author: sxx\n",
    "\"\"\"\n",
    "import time\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import traceback \n",
    "\n",
    "from predict import load_data as load_data\n",
    "from predict import transform_data as transform_data\n",
    "from predict import format_data as format_data\n",
    "from predict import divide_data as divide_data\n",
    "from predict import LstmModel as LstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time=time.strftime('%Y-%m-%d-%H-%M',time.localtime())\n",
    "\n",
    "def experiments(params):\n",
    "    print (\"epoch:\",params['epoch'],\" batch_size: \",params['batch'])\n",
    "    csvfile = './data/health_1799.csv'\n",
    "    x,y = load_data(csvfile)\n",
    "    x_,y_ = transform_data(x,y,False)\n",
    "    datax,datay = format_data(x_,y_)\n",
    "    trainX,trainY,validX,validY,testX,testY = divide_data(datax,datay)\n",
    "    \n",
    "    try:\n",
    "        ##调试模型epoch,batch_size,learnrate\n",
    "        #model = LstmModel(epoches=params['epoch'], batch_size=params['batch'],lr=params['lr'])\n",
    "\n",
    "        ##测试模型units,dropout_rate\n",
    "        model = LstmModel(units=params['units'],dr=params['dr'],lr=0.01,epoches=10,batch_size=4)\n",
    "        health_model = model.create_model()\n",
    "        save_path = './models/health_{0}.h5'.format(current_time)\n",
    "        model.train_model_1(trainX,trainY,validX,validY,save_path)\n",
    "        testPredict = health_model.predict(testX)\n",
    "        print (testY,\"-->\",testPredict)\n",
    "    except Exception as e:\n",
    "        print (\"something happen:\",repr(e))\n",
    "        print ('-' * 20)\n",
    "        with open(\"./data/err.log\",\"a\") as logf:\n",
    "            traceback.print_exc(file=logf)\n",
    "        return {'loss': 999999, 'status': STATUS_OK}\n",
    "    \n",
    "    mse = np.mean(np.square(testPredict - testY))\n",
    "    print (\"mse:\",mse)\n",
    "    print ('-' * 20)\n",
    "\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7  batch_size:  156\n",
      "LSTM model unit1_size:12.0 unit2_size:8.0 unit3_size:12.0 unit4_size:4.0 unit5_size:8.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 12)            1200      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 4)                 272       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,729\n",
      "Trainable params: 4,673\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 1.1213 - val_loss: 0.4569\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45685, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.6122 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45685 to 0.17230, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2566 - val_loss: 0.0923\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17230 to 0.09227, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0755 - val_loss: 0.0283\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09227 to 0.02829, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0274 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02829 to 0.01191, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0125 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01191 to 0.00695, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00695 to 0.00582, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00582 to 0.00503, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00503 to 0.00448, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00448 to 0.00408, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.9245873  0.9106046  0.9133418  0.925472   0.9313456 ]\n",
      " [0.93003833 0.9113423  0.9179472  0.9283049  0.9348868 ]\n",
      " [0.9261454  0.9075975  0.9140327  0.9258466  0.93439704]\n",
      " [0.9289515  0.9113905  0.9147772  0.92928076 0.9367769 ]\n",
      " [0.9244859  0.909495   0.9100526  0.92723054 0.93549496]\n",
      " [0.922227   0.9103294  0.9080563  0.92643964 0.93373287]\n",
      " [0.9199744  0.9095846  0.90585214 0.9253936  0.93287826]\n",
      " [0.92230177 0.9111932  0.90827346 0.9266062  0.9332541 ]\n",
      " [0.9213597  0.9104211  0.90785515 0.9257269  0.93251085]\n",
      " [0.91899693 0.90759116 0.90666234 0.923381   0.9312053 ]]\n",
      "mse: 0.007479143623359431\n",
      "--------------------\n",
      "epoch: 229  batch_size:  10\n",
      "LSTM model unit1_size:16.0 unit2_size:8.0 unit3_size:8.0 unit4_size:8.0 unit5_size:6.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 15, 16)            4416      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 16)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 15, 16)            64        \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 15, 8)             800       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,933\n",
      "Trainable params: 5,869\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 1.0432 - val_loss: 0.6946\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00408\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5247 - val_loss: 0.3906\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00408\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1442 - val_loss: 0.2096\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00408\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0293 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00408\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00408\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00408\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00408\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00408 to 0.00408, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00408 to 0.00402, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00402 to 0.00400, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.9542364  0.97678673 0.967881   0.965418   0.9535727 ]\n",
      " [0.94653285 0.9735813  0.97598404 0.9686651  0.9553051 ]\n",
      " [0.9388016  0.9721928  0.9766509  0.96879625 0.95334065]\n",
      " [0.9368099  0.970711   0.9777877  0.9697904  0.95232356]\n",
      " [0.93804985 0.9700004  0.9782069  0.9715853  0.95216495]\n",
      " [0.9374107  0.9696049  0.9769268  0.9707383  0.9510873 ]\n",
      " [0.937681   0.9720455  0.9764581  0.97085893 0.9538218 ]\n",
      " [0.9374016  0.9732497  0.9752719  0.96997863 0.95422536]\n",
      " [0.94466376 0.9759607  0.9769136  0.97239894 0.9569635 ]\n",
      " [0.94394827 0.9768379  0.9773162  0.9716225  0.9564033 ]]\n",
      "mse: 0.008205486957619355\n",
      "--------------------\n",
      "epoch: 240  batch_size:  117\n",
      "LSTM model unit1_size:12.0 unit2_size:8.0 unit3_size:8.0 unit4_size:8.0 unit5_size:6.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 15, 8)             672       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,493\n",
      "Trainable params: 4,437\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 0.9986 - val_loss: 1.2321\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00400\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4818 - val_loss: 0.4331\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00400\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1318 - val_loss: 0.0787\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00400\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0312 - val_loss: 0.0259\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00400\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0138 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00400 to 0.00363, saving model to ./models/health_checkpoint_2018-08-03-10-11.hdf5\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0077 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00363\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0061 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00363\n",
      "Epoch 00007: early stopping\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.9757099  0.9690907  0.9641468  0.96817243 0.97695035]\n",
      " [0.9743617  0.96877766 0.9619561  0.9669497  0.9744634 ]\n",
      " [0.9747404  0.96848375 0.9622899  0.9666954  0.97470474]\n",
      " [0.9740832  0.96773744 0.96386963 0.96621096 0.9748115 ]\n",
      " [0.97410244 0.9669207  0.96547854 0.965913   0.97554255]\n",
      " [0.97308505 0.9655956  0.96708065 0.9647525  0.97569835]\n",
      " [0.97307265 0.96475196 0.9678919  0.9639312  0.9763797 ]\n",
      " [0.9732849  0.9645288  0.9670264  0.96380985 0.97672015]\n",
      " [0.9746052  0.9666374  0.9666718  0.96575844 0.9771577 ]\n",
      " [0.975332   0.96782553 0.9661495  0.9670977  0.9772193 ]]\n",
      "mse: 0.008491501586542095\n",
      "--------------------\n",
      "epoch: 70  batch_size:  78\n",
      "LSTM model unit1_size:16.0 unit2_size:8.0 unit3_size:12.0 unit4_size:8.0 unit5_size:8.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 15, 16)            4416      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 15, 16)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 15, 16)            64        \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 15, 12)            1392      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 8)                 672       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 6,669\n",
      "Trainable params: 6,597\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 1.0502 - val_loss: 1.4888\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00363\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4940 - val_loss: 0.1280\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00363\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1255 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00363\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0232 - val_loss: 0.0185\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00363\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0097 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00363\n",
      "Epoch 00005: early stopping\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.8989924  0.8862237  0.9004698  0.8802644  0.90294343]\n",
      " [0.8923327  0.8792666  0.89879435 0.86829555 0.8963691 ]\n",
      " [0.8919012  0.8780094  0.8963788  0.86982894 0.8965804 ]\n",
      " [0.89803916 0.8842511  0.90036446 0.878168   0.9021494 ]\n",
      " [0.897093   0.8831366  0.90318793 0.87623185 0.90051323]\n",
      " [0.89517945 0.8817818  0.8994697  0.87650025 0.8984996 ]\n",
      " [0.8897173  0.87769955 0.8897601  0.86843824 0.89423406]\n",
      " [0.8893528  0.8781531  0.8847777  0.8670679  0.89482677]\n",
      " [0.8874328  0.87640744 0.8842455  0.86424595 0.893242  ]\n",
      " [0.88024616 0.87175643 0.8725388  0.8536433  0.88665396]]\n",
      "mse: 0.00978706875782166\n",
      "--------------------\n",
      "epoch: 370  batch_size:  101\n",
      "LSTM model unit1_size:16.0 unit2_size:8.0 unit3_size:12.0 unit4_size:4.0 unit5_size:6.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 15, 16)            4416      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 15, 16)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 15, 16)            64        \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 15, 12)            1392      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 4)                 272       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 6,233\n",
      "Trainable params: 6,169\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 1.0126 - val_loss: 0.6773\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00363\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5742 - val_loss: 0.6103\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00363\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2204 - val_loss: 0.3738\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00363\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0740 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00363\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0240 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00363\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0113 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00363\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0075 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00363\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0051 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00363\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00363\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00363\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.95156264 0.9550761  0.9095965  0.96148616 0.95563114]\n",
      " [0.95577484 0.95865965 0.916919   0.9659551  0.9599672 ]\n",
      " [0.9561502  0.95912933 0.9156791  0.96658325 0.96045244]\n",
      " [0.9565009  0.9593971  0.91689116 0.96690696 0.9608226 ]\n",
      " [0.95733154 0.95969826 0.921983   0.96703076 0.96112144]\n",
      " [0.9575444  0.95915353 0.93127906 0.9661337  0.9609852 ]\n",
      " [0.95492184 0.95663357 0.9368361  0.9634753  0.9597831 ]\n",
      " [0.95451033 0.9564459  0.9336092  0.963232   0.95923924]\n",
      " [0.9545568  0.95651215 0.93139917 0.963192   0.9588555 ]\n",
      " [0.95382786 0.9557196  0.9318656  0.9624504  0.95821816]]\n",
      "mse: 0.00789497973170125\n",
      "--------------------\n",
      "best:  {'activation': 2, 'batch': 156, 'dr': 0.26647266397637004, 'ds_units5': 8.0, 'epoch': 7, 'lr': 0.0028688204933912578, 'ls_units1': 12.0, 'ls_units2': 8.0, 'ls_units3': 12.0, 'ls_units4': 4.0}\n",
      "hyperoptparam end\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    space = {\n",
    "        'units':{\n",
    "        'ls_units1': hp.quniform('ls_units1',12,16,4),\n",
    "        'ls_units2': hp.quniform('ls_units2',8,12,4),\n",
    "        'ls_units3': hp.quniform('ls_units3',8,12,4),\n",
    "        'ls_units4': hp.quniform('ls_units4',4,8,4),      \n",
    "        'ds_units5': hp.quniform('ds_units5',6,8,2)},\n",
    "        'dr': hp.uniform('dr',0.1,0.6),\n",
    "        'batch': hp.randint('batch',256),\n",
    "        'epoch': hp.randint('epoch',500),\n",
    "        'lr': hp.uniform('lr',0.0001,0.01),\n",
    "        'activation': hp.choice('activation',['relu',\n",
    "                                                'sigmoid',\n",
    "                                                'tanh',\n",
    "                                                'linear'])\n",
    "        }\n",
    "    \n",
    "    trials = Trials()\n",
    "    best = fmin(experiments, space, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "    print ('best: ',best)\n",
    "    print (\"hyperoptparam end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'batch': 156, 'dr': 0.26647266397637004, 'epoch': 7, 'lr': 0.0028688204933912578, 'units': {'ds_units5': 8.0, 'ls_units1': 12.0, 'ls_units2': 8.0, 'ls_units3': 12.0, 'ls_units4': 4.0}}\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "print (hyperopt.space_eval(space, best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health",
   "language": "python",
   "name": "health"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
