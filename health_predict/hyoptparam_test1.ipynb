{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/health/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon July 16 10:08:53 2018\n",
    "\n",
    "@author: sxx\n",
    "\"\"\"\n",
    "import time\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import traceback \n",
    "\n",
    "from predict import load_data as load_data\n",
    "from predict import transform_data as transform_data\n",
    "from predict import format_data as format_data\n",
    "from predict import divide_data as divide_data\n",
    "from predict import LstmModel as LstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time=time.strftime('%Y-%m-%d-%H-%M',time.localtime())\n",
    "\n",
    "def experiments(params):\n",
    "    print (\"epoch:\",params['epoch'],\" batch_size: \",params['batch'])\n",
    "    csvfile = './data/health_1799.csv'\n",
    "    x,y = load_data(csvfile)\n",
    "    x_,y_ = transform_data(x,y,False)\n",
    "    datax,datay = format_data(x_,y_)\n",
    "    trainX,trainY,validX,validY,testX,testY = divide_data(datax,datay)\n",
    "    \n",
    "    try:\n",
    "        ##调试模型epoch,batch_size,learnrate\n",
    "        #model = LstmModel(epoches=params['epoch'], batch_size=params['batch'],lr=params['lr'])\n",
    "\n",
    "        ##测试模型units,dropout_rate\n",
    "        model = LstmModel(units=params['units'],dr=params['dr'],lr=0.01,epoches=10,batch_size=4)\n",
    "        health_model = model.create_model()\n",
    "        save_path = './models/health_{0}.h5'.format(current_time)\n",
    "        model.train_model_1(trainX,trainY,validX,validY,save_path)\n",
    "        testPredict = health_model.predict(testX)\n",
    "        print (testY,\"-->\",testPredict)\n",
    "    except Exception as e:\n",
    "        print (\"something happen:\",repr(e))\n",
    "        print ('-' * 20)\n",
    "        with open(\"./data/err.log\",\"a\") as logf:\n",
    "            traceback.print_exc(file=logf)\n",
    "        return {'loss': 999999, 'status': STATUS_OK}\n",
    "    \n",
    "    mse = np.mean(np.square(testPredict - testY))\n",
    "    print (\"mse:\",mse)\n",
    "    print ('-' * 20)\n",
    "\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 444  batch_size:  198\n",
      "LSTM model unit1_size:12 unit2_size:8 unit3_size:8 unit4_size:4 unit5_size:6 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 8)             672       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,121\n",
      "Trainable params: 4,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 0.9538 - val_loss: 0.2437\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24367, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4769 - val_loss: 0.0988\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24367 to 0.09878, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1946 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09878 to 0.02092, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0707 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02092 to 0.00975, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0288 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00975 to 0.00763, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0151 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00763 to 0.00686, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0124 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00686 to 0.00553, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00553 to 0.00460, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00460 to 0.00412, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00412 to 0.00384, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.9398143  0.92988586 0.91421217 0.92245555 0.936006  ]\n",
      " [0.94091874 0.93118036 0.91566277 0.9238405  0.93723685]\n",
      " [0.9416614  0.93247527 0.91822565 0.9257865  0.938333  ]\n",
      " [0.94427115 0.9352751  0.9211589  0.9287375  0.9410434 ]\n",
      " [0.94574463 0.9368522  0.92315394 0.93048924 0.9425976 ]\n",
      " [0.9460541  0.93713397 0.92299235 0.93065506 0.9428523 ]\n",
      " [0.9456233  0.93687296 0.9234442  0.9307194  0.9425392 ]\n",
      " [0.9451458  0.93644214 0.9230023  0.93027747 0.9420942 ]\n",
      " [0.9415689  0.9324037  0.9152491  0.92523944 0.9379057 ]\n",
      " [0.9398538  0.9308757  0.91479325 0.92430264 0.93627053]]\n",
      "mse: 0.007478724114630277\n",
      "--------------------\n",
      "epoch: 20  batch_size:  21\n",
      "LSTM model unit1_size:12 unit2_size:8 unit3_size:8 unit4_size:4 unit5_size:6 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 15, 8)             672       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,121\n",
      "Trainable params: 4,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.9720 - val_loss: 0.3796\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00384\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5139 - val_loss: 0.1230\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00384\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.2012 - val_loss: 0.2883\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00384\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0608 - val_loss: 0.0425\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00384\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0230 - val_loss: 0.0147\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00384\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00384\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00384\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0057 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00384\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00384 to 0.00367, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00367 to 0.00356, saving model to ./models/health_checkpoint_2018-08-03-13-14.hdf5\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.9380464  0.9272213  0.9358179  0.9341223  0.93022287]\n",
      " [0.9378503  0.9288119  0.9350772  0.93469864 0.9304348 ]\n",
      " [0.9371567  0.9298199  0.9346899  0.9348177  0.9319434 ]\n",
      " [0.94043833 0.93253344 0.93913394 0.9380777  0.9373593 ]\n",
      " [0.9448234  0.93689424 0.9414569  0.943523   0.9403539 ]\n",
      " [0.94365263 0.93548876 0.941486   0.94182533 0.94020194]\n",
      " [0.9435643  0.9346342  0.9424324  0.94123375 0.9410147 ]\n",
      " [0.94389033 0.93511873 0.94228053 0.9417069  0.9407506 ]\n",
      " [0.9428869  0.93461365 0.9415671  0.9402967  0.93919265]\n",
      " [0.9437505  0.93555975 0.9424352  0.94106793 0.93976694]]\n",
      "mse: 0.007390543679301072\n",
      "--------------------\n",
      "epoch: 92  batch_size:  180\n",
      "LSTM model unit1_size:12 unit2_size:8 unit3_size:8 unit4_size:4 unit5_size:6 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 15, 8)             672       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,121\n",
      "Trainable params: 4,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 1.0436 - val_loss: 1.2592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00356\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4840 - val_loss: 0.3569\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00356\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1775 - val_loss: 0.1225\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00356\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0631 - val_loss: 0.0232\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00356\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0217 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00356\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0107 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00356\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0071 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00356\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00356\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00356\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00356\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.9139763  0.9279664  0.9470836  0.94872695 0.93007797]\n",
      " [0.91769713 0.92798495 0.94585687 0.94232744 0.9310731 ]\n",
      " [0.9221487  0.93295956 0.9481472  0.93959165 0.93414205]\n",
      " [0.9281831  0.9361226  0.9505204  0.9377289  0.93859017]\n",
      " [0.92824775 0.936723   0.95240426 0.94342566 0.93996775]\n",
      " [0.925334   0.9373095  0.9533243  0.94820035 0.9390032 ]\n",
      " [0.921426   0.9319973  0.9510656  0.95043373 0.93634343]\n",
      " [0.91872495 0.9298352  0.94956714 0.95039016 0.93419516]\n",
      " [0.9200565  0.9309438  0.95030844 0.95037436 0.93524665]\n",
      " [0.9209121  0.93050355 0.9499907  0.94930136 0.935543  ]]\n",
      "mse: 0.007369576514228301\n",
      "--------------------\n",
      "epoch: 162  batch_size:  41\n",
      "LSTM model unit1_size:12 unit2_size:8 unit3_size:8 unit4_size:4 unit5_size:6 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 15, 8)             672       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,121\n",
      "Trainable params: 4,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 1.0002 - val_loss: 1.2572\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00356\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.5358 - val_loss: 0.3839\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00356\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1963 - val_loss: 0.0717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00356\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0518 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00356\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0218 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00356\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00356\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0082 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00356\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0058 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00356\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0049 - val_loss: 0.0078\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00356\n",
      "Epoch 00009: early stopping\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.867404   0.90299076 0.9033026  0.8571172  0.89921635]\n",
      " [0.86750853 0.90613866 0.906591   0.8612298  0.90326035]\n",
      " [0.8632511  0.9050147  0.90386325 0.85960424 0.9025232 ]\n",
      " [0.86308265 0.90346956 0.90093136 0.85404146 0.89950645]\n",
      " [0.8632662  0.9061279  0.903876   0.85476005 0.90183437]\n",
      " [0.86383605 0.9058679  0.89999926 0.846481   0.8993599 ]\n",
      " [0.8662755  0.90687406 0.90210664 0.84676534 0.89981043]\n",
      " [0.86470467 0.9057003  0.8996022  0.844253   0.8983807 ]\n",
      " [0.86793184 0.90971506 0.90338224 0.8459753  0.90212363]\n",
      " [0.8657145  0.908358   0.90122455 0.84367037 0.90055776]]\n",
      "mse: 0.010143230738501485\n",
      "--------------------\n",
      "epoch: 234  batch_size:  9\n",
      "LSTM model unit1_size:12 unit2_size:8 unit3_size:8 unit4_size:4 unit5_size:6 \n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 15, 12)            3120      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 15, 12)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 15, 12)            48        \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 15, 8)             672       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 15, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 8)             32        \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 4,121\n",
      "Trainable params: 4,073\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "Train on 69 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 0.9823 - val_loss: 0.4423\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00356\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.4785 - val_loss: 0.1421\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00356\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1581 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00356\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0403 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00356\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0179 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00356\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00356\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00356\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00356\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00356\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00356\n",
      "[[0.975 0.96  0.97  0.975 0.96 ]\n",
      " [0.96  0.97  0.975 0.96  0.96 ]\n",
      " [0.97  0.975 0.96  0.96  0.95 ]\n",
      " [0.975 0.96  0.96  0.95  0.68 ]\n",
      " [0.96  0.96  0.95  0.68  0.97 ]\n",
      " [0.96  0.95  0.68  0.97  0.95 ]\n",
      " [0.95  0.68  0.97  0.95  0.96 ]\n",
      " [0.68  0.97  0.95  0.96  0.965]\n",
      " [0.97  0.95  0.96  0.965 0.97 ]\n",
      " [0.95  0.96  0.965 0.97  0.97 ]] --> [[0.91272    0.937537   0.94182205 0.9257941  0.918323  ]\n",
      " [0.91195124 0.9348738  0.9385823  0.9229474  0.91651   ]\n",
      " [0.91210645 0.9354567  0.9392978  0.9235704  0.9168975 ]\n",
      " [0.9098979  0.9346767  0.9366799  0.9210131  0.9152386 ]\n",
      " [0.91025376 0.9345998  0.936766   0.92114353 0.9154015 ]\n",
      " [0.9093213  0.9344162  0.935816   0.9201971  0.914777  ]\n",
      " [0.9073611  0.93466866 0.93459815 0.9188564  0.9138019 ]\n",
      " [0.9074721  0.9344792  0.93447655 0.91877544 0.91376483]\n",
      " [0.908199   0.93497074 0.93551636 0.91975594 0.914432  ]\n",
      " [0.9083447  0.9343108  0.9349529  0.91931754 0.9141691 ]]\n",
      "mse: 0.007412042730829903\n",
      "--------------------\n",
      "best:  {'activation': 3, 'batch': 180, 'dr': 0.21504192960744692, 'ds_units5': 0, 'epoch': 92, 'lr': 0.00934276179215912, 'ls_units1': 0, 'ls_units2': 0, 'ls_units3': 0, 'ls_units4': 0}\n",
      "hyperoptparam end\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    space = {\n",
    "        'units':{\n",
    "        'ls_units1': hp.choice('ls_units1',[i for i in range(12,16,4)]),\n",
    "        'ls_units2': hp.choice('ls_units2',[i for i in range(8,12,4)]),\n",
    "        'ls_units3': hp.choice('ls_units3',[i for i in range(8,12,4)]),\n",
    "        'ls_units4': hp.choice('ls_units4',[i for i in range(4,8,4)]),      \n",
    "        'ds_units5': hp.choice('ds_units5',[i for i in range(6,8,2)])},\n",
    "        'dr': hp.uniform('dr',0.1,0.6),\n",
    "        'batch': hp.randint('batch',256),\n",
    "        'epoch': hp.randint('epoch',500),\n",
    "        'lr': hp.uniform('lr',0.0001,0.01),\n",
    "        'activation': hp.choice('activation',['relu',\n",
    "                                                'sigmoid',\n",
    "                                                'tanh',\n",
    "                                                'linear'])\n",
    "        }\n",
    "    \n",
    "    trials = Trials()\n",
    "    best = fmin(experiments, space, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "    print ('best: ',best)\n",
    "    print (\"hyperoptparam end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'linear', 'batch': 180, 'dr': 0.21504192960744692, 'epoch': 92, 'lr': 0.00934276179215912, 'units': {'ds_units5': 6, 'ls_units1': 12, 'ls_units2': 8, 'ls_units3': 8, 'ls_units4': 4}}\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "print (hyperopt.space_eval(space, best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health",
   "language": "python",
   "name": "health"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
